{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class MPNNLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    Message Passing Neural Network Layer\n",
    "    This layer performs message passing operations on graph-structured data.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, edge_dim, activation=F.relu, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the MPNN Layer\n",
    "        :param hidden_dim: Dimension of node features\n",
    "        :param edge_dim: Dimension of edge features\n",
    "        :param activation: Activation function to use (default: ReLU)\n",
    "        :param dropout: Dropout rate (default: 0.0, no dropout)\n",
    "        \"\"\"\n",
    "        super(MPNNLayer, self).__init__(aggr='add')  # Use 'add' aggregation for messages\n",
    "        self.node_mlp = nn.Linear(hidden_dim, hidden_dim)  # MLP for updating node features\n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim + edge_dim + 3, hidden_dim),  # MLP for computing messages (+3 for relative position)\n",
    "            nn.BatchNorm1d(hidden_dim),  # Batch normalization for stability\n",
    "            activation(),\n",
    "            nn.Dropout(dropout) if dropout > 0 else nn.Identity(),  # Optional dropout\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, pos):\n",
    "        \"\"\"\n",
    "        Forward pass of the MPNN Layer\n",
    "        :param x: Node features\n",
    "        :param edge_index: Graph connectivity\n",
    "        :param edge_attr: Edge features\n",
    "        :param pos: Node positions in 3D space\n",
    "        :return: Updated node features\n",
    "        \"\"\"\n",
    "        # Add self-loops to include self-information in message passing\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # Create zero-attribute for self-loops\n",
    "        self_loop_attr = torch.zeros((x.size(0), edge_attr.size(1)),\n",
    "                                     device=edge_attr.device, dtype=edge_attr.dtype)\n",
    "        edge_attr = torch.cat([edge_attr, self_loop_attr], dim=0)\n",
    "        # Start propagating messages\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr, pos=pos)\n",
    "    \n",
    "    def message(self, x_i, x_j, edge_attr, pos_i, pos_j):\n",
    "        \"\"\"\n",
    "        Compute messages between nodes\n",
    "        :param x_i: Features of target nodes\n",
    "        :param x_j: Features of source nodes\n",
    "        :param edge_attr: Edge features\n",
    "        :param pos_i: Positions of target nodes\n",
    "        :param pos_j: Positions of source nodes\n",
    "        :return: Computed messages\n",
    "        \"\"\"\n",
    "        rel_pos = pos_i - pos_j  # Compute relative positions\n",
    "        # Concatenate node features, edge features, and relative position\n",
    "        return self.message_mlp(torch.cat([x_i, x_j, edge_attr, rel_pos], dim=1))\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        \"\"\"\n",
    "        Update node features\n",
    "        :param aggr_out: Aggregated messages\n",
    "        :param x: Current node features\n",
    "        :return: Updated node features\n",
    "        \"\"\"\n",
    "        return self.dropout(self.activation(self.node_mlp(x) + aggr_out))\n",
    "\n",
    "class MPNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Message Passing Neural Network (MPNN) model\n",
    "    This model consists of multiple MPNN layers followed by a global pooling operation.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, output_dim, num_layers=3, activation=F.relu, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the MPNN model\n",
    "        :param node_dim: Initial dimension of node features\n",
    "        :param edge_dim: Dimension of edge features\n",
    "        :param hidden_dim: Hidden dimension used throughout the network\n",
    "        :param output_dim: Output dimension of the model\n",
    "        :param num_layers: Number of MPNN layers to use\n",
    "        :param activation: Activation function to use\n",
    "        :param dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super(MPNN, self).__init__()\n",
    "        self.input_proj = nn.Linear(node_dim, hidden_dim)  # Project initial node features to hidden dimension\n",
    "        \n",
    "        # Create multiple MPNN layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(MPNNLayer(hidden_dim, edge_dim, activation, dropout))\n",
    "        \n",
    "        # Output MLP\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout) if dropout > 0 else nn.Identity(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass of the MPNN model\n",
    "        :param data: PyTorch Geometric data object containing graph information\n",
    "        :return: Output predictions\n",
    "        \"\"\"\n",
    "        x, edge_index, edge_attr, pos, batch = data.x, data.edge_index, data.edge_attr, data.pos, data.batch\n",
    "        \n",
    "        h = self.input_proj(x)  # Initial projection of node features\n",
    "        \n",
    "        # Apply MPNN layers with residual connections\n",
    "        for layer in self.layers:\n",
    "            h = h + layer(h, edge_index, edge_attr, pos)  # residual connection\n",
    "        \n",
    "        h = global_mean_pool(h, batch)  # Global mean pooling\n",
    "        return self.output(h)  # Final output projection\n",
    "\n",
    "# Usage example\n",
    "# model = MPNN(node_dim=32, edge_dim=16, hidden_dim=64, output_dim=10, num_layers=3, activation=F.relu, dropout=0.1)\n",
    "# output = model(data)  # data: PyTorch Geometric's DataBatch object with pos attribute"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onebind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
