{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MetaScore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMetaScore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotein2graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m protein2graph\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMetaScore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mligand2graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ligand2graph\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpdbbind2lmdb\u001b[39m(pdbbind_dir, csv_file, output_lmdb, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m'\u001b[39m, map_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1099511627776\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MetaScore'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import shutil\n",
    "\n",
    "from protein2graph import protein2graph\n",
    "from ligand2graph import ligand2graph\n",
    "\n",
    "def pdbbind2lmdb(pdbbind_dir, csv_file, output_lmdb, mode='update', map_size=1099511627776):\n",
    "    \"\"\"\n",
    "    Process PDBbind data and store in LMDB.\n",
    "    \n",
    "    :param pdbbind_dir: Directory containing PDBbind data\n",
    "    :param csv_file: Path to pdbbind.csv file containing Kd values\n",
    "    :param output_lmdb: Path to output LMDB file\n",
    "    :param mode: 'rewrite' to create a new LMDB, 'update' to update existing or create new\n",
    "    :param map_size: Maximum size database may grow to; default is 1TB\n",
    "    \"\"\"\n",
    "    if mode == 'rewrite' and os.path.exists(output_lmdb):\n",
    "        shutil.rmtree(output_lmdb)\n",
    "    \n",
    "    if mode == 'update' and os.path.exists(output_lmdb):\n",
    "        try:\n",
    "            # Test if the existing LMDB can be read\n",
    "            with lmdb.open(output_lmdb, readonly=True) as env:\n",
    "                with env.begin() as txn:\n",
    "                    test_key = list(txn.cursor().iternext(keys=True, values=False))[0]\n",
    "                    test_value = txn.get(test_key)\n",
    "                    if test_value is not None:\n",
    "                        print(f\"Existing LMDB at {output_lmdb} is valid. No action needed.\")\n",
    "                        return\n",
    "        except Exception as e:\n",
    "            print(f\"Existing LMDB at {output_lmdb} is invalid or empty. Recreating...\")\n",
    "            shutil.rmtree(output_lmdb)\n",
    "\n",
    "    # Read Kd values from CSV\n",
    "    kd_data = pd.read_csv(csv_file)\n",
    "    kd_dict = dict(zip(kd_data['pdb_id'], kd_data['kd_value']))\n",
    "\n",
    "    env = lmdb.open(output_lmdb, map_size=map_size)\n",
    "\n",
    "    with env.begin(write=True) as txn:\n",
    "        for pdb_id in tqdm(os.listdir(pdbbind_dir)):\n",
    "            pdb_dir = os.path.join(pdbbind_dir, pdb_id)\n",
    "            if not os.path.isdir(pdb_dir):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Process protein\n",
    "                protein_file = os.path.join(pdb_dir, f\"{pdb_id}_protein.pdb\")\n",
    "                protein_data = protein2graph(protein_file) if os.path.exists(protein_file) else None\n",
    "\n",
    "                # Process ligand \n",
    "                ligand_file = os.path.join(pdb_dir, f\"{pdb_id}_ligand.sdf\")\n",
    "                ligand_data = ligand2graph(ligand_file) if os.path.exists(ligand_file) else None\n",
    "                \n",
    "                # Get Kd value\n",
    "                kd_value = kd_dict.get(pdb_id)\n",
    "\n",
    "                # Create nested dictionary\n",
    "                pdb_data = {\n",
    "                    'protein_graph': protein_data,\n",
    "                    'ligand_graph': ligand_data,\n",
    "                    'kd_value': kd_value\n",
    "                }\n",
    "\n",
    "                # Store in LMDB\n",
    "                txn.put(pdb_id.encode(), pickle.dumps(pdb_data))\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pdb_id}: {str(e)}\")\n",
    "\n",
    "    env.close()\n",
    "    print(f\"Data processing complete. LMDB database saved to {output_lmdb}\")\n",
    "\n",
    "def read_from_lmdb(lmdb_path, pdb_id):\n",
    "    \"\"\"\n",
    "    Read data for a specific PDB ID from LMDB database.\n",
    "    \n",
    "    :param lmdb_path: Path to LMDB database\n",
    "    :param pdb_id: PDB ID to retrieve\n",
    "    :return: Dictionary containing protein_graph, ligand_graph, and kd_value\n",
    "    \"\"\"\n",
    "    env = lmdb.open(lmdb_path, readonly=True)\n",
    "    with env.begin() as txn:\n",
    "        data = txn.get(pdb_id.encode())\n",
    "        if data is not None:\n",
    "            return pickle.loads(data)\n",
    "    env.close()\n",
    "    return None\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    pdbbind_dir = \"./../Testset\"\n",
    "    csv_file = \"./../Testset/pdbbind.csv\"\n",
    "    output_lmdb = \"./../Testset/pdbbind.lmdb\"\n",
    "    \n",
    "    # Process and store data\n",
    "    pdbbind2lmdb(pdbbind_dir, csv_file, output_lmdb, mode='update')\n",
    "    \n",
    "    # Example of reading data\n",
    "    pdb_id = \"1a1e\"\n",
    "    pdb_data = read_from_lmdb(output_lmdb, pdb_id)\n",
    "    \n",
    "    if pdb_data is not None:\n",
    "        print(f\"Data for {pdb_id}:\")\n",
    "        if pdb_data['protein_graph'] is not None:\n",
    "            print(f\"Protein graph nodes: {pdb_data['protein_graph'].x.shape[0]}\")\n",
    "        if pdb_data['ligand_graph'] is not None:\n",
    "            print(f\"Ligand graph nodes: {pdb_data['ligand_graph'].x.shape[0]}\")\n",
    "        print(f\"Kd value: {pdb_data['kd_value']}\")\n",
    "    else:\n",
    "        print(f\"No data found for {pdb_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onebind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
